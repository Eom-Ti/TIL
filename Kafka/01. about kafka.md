# About Kafka
## Kafka
수십년 동안 우리는 데이터베이스를 사용해왔음. 이는 데이터베이스에 정보를 저장하는 프로그램을 의미하며, 세상을 사물의 관점에서 생각하도록 하는 바잇ㄱ이 주를 이룸.
이러한 사물들의 상태를 가져와 데이터베이스에 저장하는 방식은 효율적이었으나, 이런 생각들이 사물 -> 사건을 먼저생각하는 것이 더 낫다는 것을 알게되고 있음.
이러한 사건은 시간성이 중요하며, 이는 데이터베이스에서 관리하기가 힘들어짐. 이를 위해 이벤트가 발생하면 이를 로그에 기록하며 이는 대규모로 구축하기가 쉬웠음.
Kafka는 이러한 로그를 관리하는 시스템임. 카프카는 이벤트를 먼저 생각하고, 사물을 나중에 생각하도록 권장함.(Event)

기존의 모놀리스한 방식의 설계 방식은 더 이상의 확장이나 변경하기에 큰 어려움이 있음. 그러나 추세가 MSA(Micro Service Architecture)로 변해가며, 확장 및 변경에 용이한 구조가 되어가고 있음.
이러한 작은 각 서비스들은 Kafka를 통해 메시지를 소비하고 각 서버에서 그에 맞는 계산 혹은 로직을 수행하여, 다른 Kafka 주제로 해당 메시지를 생성하여 다른 서비스 및 기타 관심사에서 처리할 수 있도록 구성됨.
이렇게 모든 데이터가 **실시간 스트림**으로 흐르는 구조는 대규모 시스템에서의 **실시간**으로 분석하는 새로운 서비스를 구축하는 것들이 가능해짐.

또한 많은 시스템들이 얽혀있는 시스템구조에서 Kafka는 `connect`를 통해 각 외부 시스템간의 입력/출력을 담당할 수 있도록 제공하고 있음.
<img width="1826" height="1217" alt="image" src="https://github.com/user-attachments/assets/7fbe85e8-5b10-445a-b30e-f747d42f3748" />


### [Broker]

**Kafka Broker**는 일반적으로 `카프카`라고 불리는 시스템을 의미함. 카프카를 실행하면 카프카 서버 프로세스의 각 인스턴스(물리적 Server, Cloud instance 등)가 브로커가 됨.

이러한 Kafka Broker가 여러개 모인 그룹이 `Kafka Cluster`를 구성하게 됨.

---

#### 주요 역할

- **메시지 저장소**: Producer가 보낸 메시지를 디스크에 안전하게 저장
- **메시지 전달**: Consumer 요청에 따라 저장된 메시지를 전송
- **파티션 관리**: 토픽의 파티션들을 분산 저장하고 관리
- **복제 관리**: 데이터 손실 방지를 위해 다른 브로커에 데이터 복제

---

#### 핵심 특징

- **분산 처리**: 여러 브로커가 클러스터를 구성해 부하 분산
- **고성능**: 순차적 디스크 I/O로 높은 처리량 달성
- **내구성**: 메시지를 디스크에 영구 저장 (설정 가능한 보관 기간)
- **확장성**: 브로커 추가로 쉽게 용량과 성능 확장
- **장애 복구**: 브로커 장애 시 복제본을 통해 자동 복구
- **리더-팔로워 구조**: 각 파티션마다 하나의 리더 브로커가 읽기/쓰기 담당

---

#### Inside the Kafka Broker

<img width="2185" height="1121" alt="image" src="https://github.com/user-attachments/assets/62e74117-f8a9-47d3-b8e8-7b9ae95713ae" />

**Client 요청의 범주**
- 생성 요청
- 가져오기 요청

---

### 1. 생성 요청 (Produce Request)

#### 1) 파티션 할당

클라이언트가 카프카에 Produce하는 요청을 말한다. 이때 브로커는 구성 가능한 파티셔너를 사용하여 레코드에 할당할 토픽 파티션을 결정한다.

- **키가 존재하는 경우**: `키의 해시를 사용해 파티션을 결정`하며, 동일한 키를 가진 모든 레코드가 동일한 파티션에 할당됨
- **키가 없는 경우**: `파티션 전략`에 따라 데이터 균형을 맞춰 Produce함

#### 2) 레코드 배치

레코드를 한번에 하나씩 보낸다면 네트워크의 많은 오버헤드를 불러일으키며, 이를 위해 producer는 파티션에 할당된 레코드를 일괄 처리하여 누적함.

이러한 방식은 압축을 사용할 때 더 효과적인 압축을 제공함.

**배치 방식의 두 가지 기준**
- **시간 기준**: 이벤트 발행량이 많지 않을 경우 메시지들을 발행할 수 없는 상태가 되거나 매우 늦게 발행될 수 있음(실시간성 중요)
- **크기 기준**: 대량의 데이터를 전송하는 경우, 제한된 네트워크 환경에서 작업하는 경우, 실시간성이 크게 중요하지 않은 경우

#### 3) 네트워크 스레드가 요청을 큐에 추가

<img width="1777" height="831" alt="image" src="https://github.com/user-attachments/assets/199c02b8-5be8-4ca5-ad4e-33119591fa01" />

**처리 과정 (4단계)**
1. **요청 도착** → Socket receive buffer에 클라이언트 요청이 저장
2. **담당자 배정** → Network thread pool에서 하나의 스레드가 해당 요청을 담당
3. **데이터 변환** → Socket buffer에서 데이터를 읽어 produce request 객체로 변환
4. **대기열 등록** → 완성된 request 객체를 request queue에 추가

#### 4) I/O 스레드가 배치를 검증하고 저장

<img width="1765" height="957" alt="image" src="https://github.com/user-attachments/assets/26774ddd-7c16-45cb-b4d6-faff350b4c13" />

클라이언트의 요청이 대기열(큐)에 쌓이면, I/O 스레드 풀의 스레드가 큐에서 요청을 가져온다.

이때 **CRC(`Cyclic Redundancy Check` / 데이터 무결성 검사)** 검사를 포함한 몇가지 유효성 검사를 수행하며, 이를 커밋 로그라고 불리는 파티션의 물리적 데이터 구조에 추가한다.

---

### 커밋 로그 (Commit Log)

**커밋 로그**는 메시지들이 **시간 순서대로** 쌓이는 `Append-only`의 로그 파일로 설정한 보관 기간(기본 7일)까지 디스크에 유지한다.

디스크 상에서의 **커밋 로그**는 `세그먼트` 모음으로 구성되며, 각 세그먼트는 여러 파일로 구성되어 있다:

- **`.log` 파일**: 이벤트 데이터가 포함
- **`.index` 파일**: 레코드 오프셋을 `.log` 파일 내 해당 레코드의 위치로 매핑하는 인덱스 구조

---

### Log Compaction & Tombstone

#### Log Compaction
**사용 목적**: 같은 Key의 최신 값만 유지하고 싶을 때 (예: 사용자 프로필, 설정 정보 등)
압축 전:
key1: value1  (offset 0)
key2: value2  (offset 1)
key1: value3  (offset 2)  ← 최신값
key2: value4  (offset 3)  ← 최신값
압축 후:
key1: value3  (offset 2)  ← 최신값만 남김
key2: value4  (offset 3)  ← 최신값만 남김

#### Tombstone (삭제 마커)
key1: value1    (일반 메시지)
key1: null      ← Tombstone (삭제 마커)

**처리 과정**
1. 삭제하려면 → `key: null` 메시지 전송
2. Compaction 실행 시 → 해당 key의 모든 이전 메시지 삭제
3. 일정 시간 후 → Tombstone 자체도 삭제 (`delete.retention.ms`)

#### 전체 생명주기
1. **일반 append** → `.log` 파일에 계속 추가
2. **Segment 가득참** → 새 segment 생성
3. **Compaction 트리거** → 중복 key 정리 + Tombstone 처리
4. **오래된 데이터** → retention 정책에 따라 삭제
  https://developer.confluent.io/courses/architecture/broker/

### Topic
주제는 내구성 있는 방식으로 저장된 이벤트의 정렬된 컬렉션에 불과함. 이는 이벤트가 디스크에 기록되고 복제된다는 것을 의미함. 따라서 인프라가 운영되는 곳이라면
어디든 여러 개의 디스크, 여러 서버에 저장되기에 `하드웨어 오류로 인해 데이터가 사라지는 일이 없음`. 이러한 주제는 몇 시간, 몇 년, 무기한 등의 기간 동안 `데이터를 저장할 수 있음`.
### Partition
### Producer
### Consumer
### MetaData
이후에 더 깊게 다루겠지만 Kafka는 특정 버전(3.7.x) 이후로 `orchestration`의 주체가 **ZooKeeper** 에서 **KRAFT(Kafka Raft)**로 변경되었다.
이는 Zookeeper로 부터의 의존성을 떼어내기 위한 것으로 기존 메타데이터의 경우 ZooKeeper의 노드에서 관리했지만 KRAFT에선 이를 Kafka 클러스터 일부인 Kafka 컨트롤러 그룹 내에서 전파되도록 관리한다.

